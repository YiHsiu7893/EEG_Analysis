{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1209,"status":"ok","timestamp":1718469596365,"user":{"displayName":"林怡秀","userId":"08690569950036176555"},"user_tz":-480},"id":"UcmCFSRGZXCv"},"outputs":[],"source":["from scipy.io import loadmat\n","import pickle\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qgeKzISHt7CQ"},"outputs":[],"source":["\"\"\"\n","# this block is for getting familiar with the structure of the dataset\n","\n","# taking eeg_record1.mat for example\n","mat = loadmat('/EEG Data/eeg_record1.mat')\n","\n","#mat\n","#mat['o']\n","#mat['o']['data']\n","#mat['o']['data'][0]\n","#mat['o']['data'][0][0]\n","mat['o']['data'][0][0].shape   #(308868, 25) = 308868 samples * 25 channels\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"vVcYvs6Spqj7"},"source":["# **Dataset Preparation**"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1718469596366,"user":{"displayName":"林怡秀","userId":"08690569950036176555"},"user_tz":-480},"id":"tNO4xQy0v1pr"},"outputs":[],"source":["# frequency = 128Hz\n","fs = 128\n","\n","# 5 participants\n","n_subjects = 5\n","\n","# samples of the first 10 minutes are for 'focused'\n","# 10~20 for 'unfocused'\n","# 20~ for 'drowsed'\n","mkpt1 = int(fs*60*10)\n","mkpt2 = int(fs*60*20)\n","mkpt3 = int(fs*60*30)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":590,"status":"ok","timestamp":1718469615564,"user":{"displayName":"林怡秀","userId":"08690569950036176555"},"user_tz":-480},"id":"7yvcpMCvwrWz"},"outputs":[],"source":["# according to the paper, each participant took part in 7 experiments (except for the 5th participant who only participated in 6),\n","# but the first two were for getting familiar with the experiment, so only the last 5 were considered\n","subject_map = {1: [3, 4, 5, 6, 7], 2: [10, 11, 12, 13, 14], 3: [17, 18, 19, 20, 21], 4: [24, 25, 26, 27, 28], 5: [31, 32, 33, 34]}\n","\n","# names of useful EEG channels (14 out of 25 channels)\n","channels = ['F7','F3','P7','O1','O2','P8','AF4']\n","c_list = [4, 5, 8, 9, 10, 11, 16]"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":10208,"status":"ok","timestamp":1718469661364,"user":{"displayName":"林怡秀","userId":"08690569950036176555"},"user_tz":-480},"id":"Rk2KBzjSyQ_Z"},"outputs":[],"source":["dir = \"/EEG Data/\"\n","\n","# for each participant:\n","for s in range(1, n_subjects+1):\n","  data = {}\n","  data['channels'] = channels\n","  data['fs'] = fs\n","\n","  # for each experiment the participant has been engaged in:\n","  for i, record in enumerate(subject_map[s]):\n","    exp = {}\n","\n","    exp_data = loadmat(dir+f'eeg_record{record}.mat')\n","    # only select channels [4, 5, 8, 9, 10, 11, 16]\n","    eeg = exp_data['o']['data'][0][0][:, c_list]\n","    # print(eeg.shape)\n","\n","    # split the data into 'focused', 'unfocused', and 'drowsed' phases\n","    exp['focused'] = eeg[:mkpt1]\n","    exp['unfocused'] = eeg[mkpt1:mkpt2]\n","    exp['drowsed'] = eeg[mkpt2:mkpt3]\n","\n","    data[f'exp_{i+1}'] = exp\n","\n","  # save the data of this participant\n","  with open(f'subject_{s}.pkl', 'wb') as f:\n","    pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)"]},{"cell_type":"markdown","metadata":{"id":"cD3foA1u9gf3"},"source":["# **Visualization**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ks5o5A2_i3KY"},"outputs":[],"source":["# load the data of the first participant for example\n","with open('subject_1.pkl', 'rb') as f:\n","  data = pickle.load(f)\n","data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kULbHtPW2kR2"},"outputs":[],"source":["# plot the EEG graph of 'exp_1' during the 'focused' phase for inspection\n","fig, ax = plt.subplots(7,1)\n","fig.set_figwidth(20)\n","fig.set_figheight(40)\n","\n","num_samples = data['exp_1']['focused'].shape[0]\n","time = np.arange(num_samples) / fs\n","\n","for c in range(7):\n","  channel = data['exp_1']['focused'][:, c]\n","  ax[c].plot(time, channel)\n","  ax[c].set_xlabel('time (s)')\n","  ax[c].set_ylabel(f'Channel {channels[c]}')\n","  ax[c].set_title(channels[c])\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"mu82j8ALIHw5"},"source":["# **Data Analysis**"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":402,"status":"ok","timestamp":1718470259898,"user":{"displayName":"林怡秀","userId":"08690569950036176555"},"user_tz":-480},"id":"f-_SKxgyZd5R"},"outputs":[],"source":["subject = 1\n","\n","with open(f'subject_{subject}.pkl', 'rb') as f:\n","  data = pickle.load(f)\n","\n","phases = ['focused', 'unfocused', 'drowsed']"]},{"cell_type":"markdown","metadata":{"id":"zk0fImgx_5ex"},"source":["Lag Plot: 輸出資料分布看是否適合使用線性模型"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tNTthdyWxx55"},"outputs":[],"source":["# 輸出受試者的3個phase的7個channel資料\n","## note: change this parameter to test different lags\n","lag = 1\n","\n","for exp_num in range(len(subject_map[subject])):\n","  for phase in phases:\n","    phase_data = data[f'exp_{exp_num+1}'][phase]\n","    #print(phase_data.shape)\n","    for i in range(phase_data.shape[1]):\n","      data_series = pd.Series(phase_data[:, i])\n","      #print(\"data: \", data_series.shape)\n","      pd.plotting.lag_plot(data_series, lag=lag)\n","      plt.show()"]},{"cell_type":"markdown","metadata":{"id":"nvjvnwP-3z_M"},"source":["ADF Test: 判斷資料是否平穩 (p_value <= 0.05)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pBc8ANJprASQ"},"outputs":[],"source":["from statsmodels.tsa.stattools import adfuller\n","\n","def adf_test(series, title=''):\n","    print(f'Augmented Dickey-Fuller Test: {title}')\n","    result = adfuller(series.dropna(), autolag='AIC') # .dropna() handles differenced data\n","    labels = ['ADF test statistic', 'p-value', 'Number of lags used', 'Number of observations used']\n","    out = pd.Series(result[0:4], index=labels)\n","    for k, v in result[4].items():\n","        out[f'critical value ({k})'] = v\n","\n","    #print(out)\n","    if result[1] <= 0.05:  # 有顯著性，推翻虛無假設\n","        print(\"Data has no unit root and is stationary\")\n","        return 1\n","    else:\n","        print(\"Data has a unit root and is non-stationary\")\n","        return 0\n","\n","for exp_num in range(len(subject_map[subject])):\n","  for i, phase in enumerate(phases):\n","    phase_data = data[f'exp_{exp_num+1}'][phase]\n","    # print(phase_data[:, 0].shape)\n","    for c in range(phase_data.shape[1]):\n","      data_series = pd.DataFrame(phase_data[:, c])\n","      adf_test(data_series, title=i)\n","      print()"]},{"cell_type":"markdown","metadata":{"id":"vAS8r6dZvXLE"},"source":["# **Feature Extraction**  \n","4 methods"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":399,"status":"ok","timestamp":1718471309386,"user":{"displayName":"林怡秀","userId":"08690569950036176555"},"user_tz":-480},"id":"I17pRi0iv0lT"},"outputs":[],"source":["from scipy.signal import get_window\n","\n","# 以8秒為單位切割\n","segment_length = 8*fs\n","# 相鄰切割視窗重疊量\n","overlap = segment_length - int(fs * 0.5)\n","# 窗函數\n","window = get_window('blackman', segment_length)\n","\n","phases = ['focused', 'unfocused', 'drowsed']"]},{"cell_type":"markdown","metadata":{"id":"KFPFuwzI9nAq"},"source":["## **Method1 - Standard Statistics**\n","Standard Deviation + Skewness + Kurtosis"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1718471310325,"user":{"displayName":"林怡秀","userId":"08690569950036176555"},"user_tz":-480},"id":"f8dSetfY_cJx"},"outputs":[],"source":["from scipy.stats import kurtosis, skew\n","\n","def Stats(subject, data):\n","  processed_data = []\n","  labels = []\n","\n","  for exp_num in range(len(subject_map[subject])):\n","    for i, phase in enumerate(phases):\n","      phase_data = data[f'exp_{exp_num+1}'][phase]\n","      time_points = len(phase_data)\n","\n","      for start in range(0, time_points-segment_length+1, segment_length-overlap):\n","        end = start+segment_length\n","        segment = phase_data[start:end, :]\n","\n","        deviation = np.std(segment, axis=0)\n","        skewness = skew(segment, axis=0)\n","        kurtosis_data = kurtosis(segment, axis=0)\n","        concatenated_data = np.concatenate((deviation, skewness, kurtosis_data))\n","\n","        processed_data.append(concatenated_data)\n","        labels.append(i)\n","\n","  return np.array(processed_data), np.array(labels)"]},{"cell_type":"markdown","metadata":{"id":"NIhBduwpt6c-"},"source":["## **Method2 - STFT**"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1718471310325,"user":{"displayName":"林怡秀","userId":"08690569950036176555"},"user_tz":-480},"id":"Tw_PLPudt46x"},"outputs":[],"source":["from scipy.signal import stft\n","\n","\n","def STFT(subject, data):\n","  processed_data = []\n","  labels = []\n","\n","  for exp_num in range(len(subject_map[subject])):\n","    for i, phase in enumerate(phases):\n","      phase_data = data[f'exp_{exp_num+1}'][phase]\n","\n","      all_c_data = []\n","      for c in range(len(data['channels'])):\n","      # 計算每個channel的STFT\n","        f, t, Zxx = stft(phase_data[:, c], fs=fs, window=window, nperseg=segment_length, noverlap=overlap)\n","        all_c_data.append((np.abs(Zxx))**2)\n","\n","      # 堆疊all_c_data list為矩陣\n","      all_c_data = np.concatenate(all_c_data, axis=0)\n","      # 切割每個時間步\n","      for t in range(all_c_data.shape[1]):\n","        feature = all_c_data[:, t]\n","        vector = 10*np.log(feature+1e-10)\n","\n","        processed_data.append(vector)\n","        labels.append(i)\n","\n","  return np.array(processed_data), np.array(labels)"]},{"cell_type":"markdown","metadata":{"id":"vuzur3RuWwA7"},"source":["## **Method3- parametric spectral estimation**\n","VAR model (多變數)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1718471310325,"user":{"displayName":"林怡秀","userId":"08690569950036176555"},"user_tz":-480},"id":"kMem7IPXA3Fp"},"outputs":[],"source":["from statsmodels.tsa.api import VAR\n","\n","def Var(subject, data):\n","  processed_data = []\n","  labels = []\n","  lag = 1\n","\n","  for exp_num in range(len(subject_map[subject])):\n","    for i, phase in enumerate(phases):\n","      phase_data = data[f'exp_{exp_num+1}'][phase]\n","      time_points = len(phase_data)\n","\n","      for start in range(0, time_points-segment_length+1, segment_length-overlap):\n","        end = start+segment_length\n","        segment = phase_data[start:end, :]\n","\n","        model = VAR(segment)\n","        results = model.fit(lag)   # best: 44(11.75)\n","        # print(results.summary())\n","        # 提取係數、截距、殘差\n","        coefficients, intercepts, residuals = results.params, results.intercept, results.resid\n","        residuals = np.pad(residuals, ((lag, 0), (0, 0)), mode='constant', constant_values=0)\n","        coefficients = coefficients.reshape(-1)   # (8, 7) -> (56,)\n","        coefficients = np.tile(coefficients, (len(segment), 1))\n","        concat_data = np.concatenate((coefficients, residuals), axis=1) # (128, 63)\n","        concat_data = np.mean(concat_data, axis=0)\n","        c = len(concat_data)\n","        concat_data = np.reshape(concat_data, (1, c)) # (1, 128, 63)\n","\n","        processed_data.append(concat_data)\n","        labels.append(i)\n","\n","  processed_data = np.concatenate(processed_data, axis=0)\n","\n","  return np.array(processed_data), np.array(labels)"]},{"cell_type":"markdown","metadata":{"id":"on_gh_KPSdl-"},"source":["## **Method4- Barlett**\n","channel分開"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1718471310325,"user":{"displayName":"林怡秀","userId":"08690569950036176555"},"user_tz":-480},"id":"nAx6GLQBhAPv"},"outputs":[],"source":["from scipy.signal import welch\n","from scipy.integrate import simps\n","import seaborn as sns\n","\n","def Welch(subject, data):\n","  processed_data = []\n","  labels = []\n","  feature = 5\n","\n","  for exp_num in range(len(subject_map[subject])):\n","    for i, phase in enumerate(phases):\n","      phase_data = data[f'exp_{exp_num+1}'][phase]\n","      time_points = len(phase_data)\n","\n","      for start in range(0, time_points-segment_length+1, segment_length-overlap):\n","        features_channels = np.empty((feature, 0))\n","        end = start+segment_length\n","        segment = phase_data[start:end, :]\n","\n","        # 對每個channel計算 Welch 方法的功率谱密度\n","        for channel in range(segment.shape[1]):\n","            freqs, psd = welch(segment[:, channel], fs=fs, nperseg=segment_length)\n","            # Frequency resolution\n","            freq_res = freqs[1] - freqs[0]  # = 1 / 4 = 0.25\n","            total_power = simps(psd, dx=freq_res)\n","            delta_power = simps(psd[(freqs >= 0.5) & (freqs < 4)], dx=freq_res) / total_power\n","            theta_power = simps(psd[(freqs >= 4) & (freqs < 8)], dx=freq_res) / total_power\n","            alpha_power = simps(psd[(freqs >= 8) & (freqs < 13)], dx=freq_res) / total_power\n","            beta_power = simps(psd[(freqs >= 13) & (freqs < 30)], dx=freq_res) / total_power\n","            gamma_power = simps(psd[(freqs >= 30)], dx=freq_res) / total_power\n","            features = np.array([delta_power, theta_power, alpha_power, beta_power, gamma_power])  # 有加入delta\n","            # features = np.array([theta_power, alpha_power, beta_power, gamma_power])      # 不加入delta\n","            # print(\"feature: \", features)\n","            features = features.reshape(-1, 1)\n","            # print(\"feature: \", features.shape)\n","\n","            features_channels = np.concatenate((features_channels, features), axis=1)\n","            # print(\"scale feature: \", features_channels.shape)\n","\n","        labels.append(i)\n","        processed_data.append(features_channels)\n","\n","  processed_data = np.array(processed_data)\n","  concat_processed_data = processed_data.reshape(processed_data.shape[0], processed_data.shape[1] * processed_data.shape[2])\n","  concat_processed_data = np.array(concat_processed_data)\n","  labels = np.array(labels)\n","  #print(\"labels: \", len(labels))\n","  #print(\"process: \", len(processed_data))\n","  return concat_processed_data, labels"]},{"cell_type":"markdown","metadata":{"id":"TV4pYLKpw6v6"},"source":["# **Testing**\n","Show the results of one subject. (Subject-Specific paradigm)"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":1349,"status":"ok","timestamp":1718471852951,"user":{"displayName":"林怡秀","userId":"08690569950036176555"},"user_tz":-480},"id":"Voi64klqypXU"},"outputs":[],"source":["from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.decomposition import PCA\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","\n","# Subject-Specific paradigm:\n","# train the classifier individually for each participant based on the data collected for that participant\n","\n","## note: change this parameter for inspecting other participants\n","subject = 1\n","\n","with open(f'subject_{subject}.pkl', 'rb') as f:\n","  data = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MI5HJZEhw-Lm"},"outputs":[],"source":["# method 1\n","processed_data, labels = Stats(subject, data)  # processed_data.shape = (17775, 21)\n","train_x, test_x, train_y, test_y = train_test_split(processed_data, labels, test_size=0.2)\n","\n","svm = SVC(C=40.0, kernel='rbf', gamma='scale')\n","print(\"------\\nMethod 1\\n------\")\n","\n","cv_scores = cross_val_score(svm, train_x, train_y, cv=5)\n","print(\"Cross-Validation scores:\", cv_scores)\n","print(\"Average Cross-Validation score:\", np.mean(cv_scores))\n","\n","svm.fit(train_x,train_y)\n","train_score = svm.score(train_x, train_y)\n","test_score = svm.score(test_x, test_y)\n","\n","print('\\nTraining score:', train_score)\n","print('Testing score:', test_score)\n","md1 = [round(train_score, 2), round(test_score, 2)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LBWn-vLazP6I"},"outputs":[],"source":["# method 2\n","# 初始化PCA，並指定要保留的主成分數量\n","pca = PCA(n_components=200)\n","\n","processed_data, labels = STFT(subject, data)  # processed_data.shape = (18015, 252)\n","\n","# 對數據進行PCA\n","processed_data = pca.fit_transform(processed_data)\n","train_x, test_x, train_y, test_y = train_test_split(processed_data, labels, test_size=0.2)\n","\n","svm = SVC(C=5.0, kernel='rbf', gamma='scale')\n","print(\"------\\nMethod 2\\n------\")\n","\n","cv_scores = cross_val_score(svm, train_x, train_y, cv=5)\n","print(\"Cross-Validation scores:\", cv_scores)\n","print(\"Average Cross-Validation score:\", np.mean(cv_scores))\n","\n","svm.fit(train_x,train_y)\n","train_score = svm.score(train_x, train_y)\n","test_score = svm.score(test_x, test_y)\n","\n","print('\\nTraining score:', train_score)\n","print('Testing score:', test_score)\n","md2 = [round(train_score, 2), round(test_score, 2)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6mQybp2Pvkwi"},"outputs":[],"source":["# method 3\n","processed_data, labels = Var(subject, data)\n","train_x, test_x, train_y, test_y = train_test_split(processed_data, labels, test_size=0.2)\n","\n","svm = SVC(C=40.0, kernel='rbf', gamma='scale')\n","print(\"------\\nMethod 3\\n------\")\n","\n","cv_scores = cross_val_score(svm, train_x, train_y, cv=5)\n","print(\"Cross-Validation scores:\", cv_scores)\n","print(\"Average Cross-Validation score:\", np.mean(cv_scores))\n","\n","svm.fit(train_x,train_y)\n","train_score = svm.score(train_x, train_y)\n","test_score = svm.score(test_x, test_y)\n","\n","print('\\nTraining score:', train_score)\n","print('Testing score:', test_score)\n","md3 = [round(train_score, 2), round(test_score, 2)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_QKLl9tWv51J"},"outputs":[],"source":["# method 4\n","processed_data, labels = Welch(subject, data)\n","train_x, test_x, train_y, test_y = train_test_split(processed_data, labels, test_size=0.2)\n","\n","svm = SVC(C=20.0, kernel='rbf', gamma='scale')\n","print(\"------\\nMethod 4\\n------\")\n","\n","cv_scores = cross_val_score(svm, train_x, train_y, cv=5)\n","print(\"Cross-Validation scores:\", cv_scores)\n","print(\"Average Cross-Validation score:\", np.mean(cv_scores))\n","\n","svm.fit(train_x,train_y)\n","train_score = svm.score(train_x, train_y)\n","test_score = svm.score(test_x, test_y)\n","\n","print('\\nTraining score:', train_score)\n","print('Testing score:', test_score)\n","md4 = [round(train_score, 2), round(test_score, 2)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hhlVlfQv2sUn"},"outputs":[],"source":["labels = ['Training', 'Testing']\n","x = np.arange(len(labels))\n","width = 0.2  # 柱狀圖的寬度\n","\n","fig, ax = plt.subplots()\n","\n","# 繪製四組資料的柱狀圖\n","rects1 = ax.bar(x - 3*width/2, md1, width, label='Stats', color='skyblue')\n","rects2 = ax.bar(x - width/2, md2, width, label='STFT', color='lightgreen')\n","rects3 = ax.bar(x + width/2, md3, width, label='VAR', color='lightpink')\n","rects4 = ax.bar(x + 3*width/2, md4, width, label='PSD', color='gold')\n","\n","ax.set_xlabel('Accuracy')\n","ax.set_title(f'Comparison of Four Methods for subject {subject}')\n","ax.set_xticks(x)\n","ax.set_xticklabels(labels)\n","ax.legend()\n","\n","# 顯示圖表\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Mvl9FhO1EJGW"},"source":["# **Results**\n","Show the testing accuracy for all subjects using\n","different feature extraction methods."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DFrks_zPeAms"},"outputs":[],"source":["md1 = []\n","md2 = []\n","md3 = []\n","md4 = []\n","\n","for s in range(5):\n","  subject = s+1\n","\n","  with open(f'subject_{subject}.pkl', 'rb') as f:\n","    data = pickle.load(f)\n","\n","  # method 1\n","  processed_data, labels = Stats(subject, data)  # processed_data.shape = (17775, 21)\n","  train_x, test_x, train_y, test_y = train_test_split(processed_data, labels, test_size=0.2)\n","\n","  svm = SVC(C=40.0, kernel='rbf', gamma='scale')\n","  print(\"------\\nMethod 1\\n------\")\n","\n","  cv_scores = cross_val_score(svm, train_x, train_y, cv=5)\n","  print(\"Cross-Validation scores:\", cv_scores)\n","  print(\"Average Cross-Validation score:\", np.mean(cv_scores))\n","\n","  svm.fit(train_x,train_y)\n","  train_score = svm.score(train_x, train_y)\n","  test_score = svm.score(test_x, test_y)\n","\n","  print('\\nTraining score:', train_score)\n","  print('Testing score:', test_score)\n","  md1.append(round(test_score, 2))\n","\n","\n","  # method 2\n","  pca = PCA(n_components=200)\n","\n","  processed_data, labels = STFT(subject, data)  # processed_data.shape = (18015, 252)\n","  processed_data = pca.fit_transform(processed_data)\n","  train_x, test_x, train_y, test_y = train_test_split(processed_data, labels, test_size=0.2)\n","\n","  svm = SVC(C=5.0, kernel='rbf', gamma='scale')\n","  print(\"------\\nMethod 2\\n------\")\n","\n","  cv_scores = cross_val_score(svm, train_x, train_y, cv=5)\n","  print(\"Cross-Validation scores:\", cv_scores)\n","  print(\"Average Cross-Validation score:\", np.mean(cv_scores))\n","\n","  svm.fit(train_x,train_y)\n","  train_score = svm.score(train_x, train_y)\n","  test_score = svm.score(test_x, test_y)\n","\n","  print('\\nTraining score:', train_score)\n","  print('Testing score:', test_score)\n","  md2.append(round(test_score, 2))\n","\n","\n","  # method 3\n","  processed_data, labels = Var(subject, data)\n","  train_x, test_x, train_y, test_y = train_test_split(processed_data, labels, test_size=0.2)\n","\n","  svm = SVC(C=40.0, kernel='rbf', gamma='scale')\n","  print(\"------\\nMethod 3\\n------\")\n","\n","  cv_scores = cross_val_score(svm, train_x, train_y, cv=5)\n","  print(\"Cross-Validation scores:\", cv_scores)\n","  print(\"Average Cross-Validation score:\", np.mean(cv_scores))\n","\n","  svm.fit(train_x,train_y)\n","  train_score = svm.score(train_x, train_y)\n","  test_score = svm.score(test_x, test_y)\n","\n","  print('\\nTraining score:', train_score)\n","  print('Testing score:', test_score)\n","  md3.append(round(test_score, 2))\n","\n","\n","  # method 4\n","  processed_data, labels = Welch(subject, data)\n","  train_x, test_x, train_y, test_y = train_test_split(processed_data, labels, test_size=0.2)\n","\n","  svm = SVC(C=20.0, kernel='rbf', gamma='scale')\n","  print(\"------\\nMethod 4\\n------\")\n","\n","  cv_scores = cross_val_score(svm, train_x, train_y, cv=5)\n","  print(\"Cross-Validation scores:\", cv_scores)\n","  print(\"Average Cross-Validation score:\", np.mean(cv_scores))\n","\n","  svm.fit(train_x,train_y)\n","  train_score = svm.score(train_x, train_y)\n","  test_score = svm.score(test_x, test_y)\n","\n","  print('\\nTraining score:', train_score)\n","  print('Testing score:', test_score)\n","  md4.append(round(test_score, 2))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1718473179266,"user":{"displayName":"林怡秀","userId":"08690569950036176555"},"user_tz":-480},"id":"dmJsVvVljqGx"},"outputs":[],"source":["labels = ['#1', '#2', '#3', '#4', '#5']\n","x = np.arange(len(labels))\n","width = 0.2  # 柱狀圖的寬度\n","\n","fig, ax = plt.subplots()\n","\n","# 繪製四組資料的柱狀圖\n","rects1 = ax.bar(x - 3*width/2, md1, width, label='Stats', color='skyblue')\n","rects2 = ax.bar(x - width/2, md2, width, label='STFT', color='lightgreen')\n","rects3 = ax.bar(x + width/2, md3, width, label='VAR', color='lightpink')\n","rects4 = ax.bar(x + 3*width/2, md4, width, label='PSD', color='gold')\n","\n","ax.set_xlabel('Subject')\n","ax.set_ylabel('Accuracy')\n","ax.set_title('window size = 8s')\n","ax.set_xticks(x)\n","ax.set_xticklabels(labels)\n","ax.legend()\n","\n","# 顯示圖表\n","plt.show()"]}],"metadata":{"colab":{"collapsed_sections":["cD3foA1u9gf3"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
